# MOSHI v10.0 - Tensor Concatenation Approach

**Date**: 2025-11-08
**Status**: ⏳ AWAITING USER VERIFICATION (Whisper API NOT reliable)
**Version**: v10.0

## Summary

Implemented complete rewrite to match `gen.rs` tensor handling exactly. Changed from immediate `Vec<f32>` conversion to collecting `Vec<Tensor>` and concatenating at the end.

## The Fix (v10.0)

### Key Change

**BEFORE (v9.1 and earlier - FAILED):**
```rust
let mut all_audio_samples = Vec::new();

// In decode loop:
if let Some(pcm_tensor) = decoded.as_option() {
    let mut frame_samples = pcm_tensor.flatten_all()?.to_vec1::<f32>()?;
    frame_samples.reverse();  // v9.1 attempted fix
    all_audio_samples.extend(frame_samples);
}
```

**AFTER (v10.0 - Match gen.rs exactly):**
```rust
let mut out_pcm_tensors: Vec<Tensor> = Vec::new();

// In decode loop:
if let Some(pcm_tensor) = decoded.as_option() {
    out_pcm_tensors.push(pcm_tensor.clone());
}

// After all decoding complete:
let concatenated = Tensor::cat(&out_pcm_tensors, 2)?;  // Concatenate along time dimension
let all_audio_samples = concatenated.i((0, 0))?.to_vec1::<f32>()?;  // Extract using indexing
```

## Why This Should Work

### The Problem with `.flatten_all()`

When you have a tensor with shape `(1, 1, num_samples)`:
- `.flatten_all()` flattens all dimensions, but may not preserve correct sample ordering
- The flattening order depends on tensor memory layout (C-contiguous vs F-contiguous)

### The Solution with `.i((0, 0))`

- `.i((0, 0))` explicitly indexes `[batch=0][channel=0]`, giving you the time series
- This preserves the exact sample ordering as stored in the tensor
- Matches gen.rs exactly, which produces working audio

### Tensor Concatenation

By collecting tensors first:
- Each `decode_step()` returns a tensor with shape `(1, 1, ~1920)` (80ms at 24kHz)
- `Tensor::cat(&tensors, 2)` concatenates along dimension 2 (time)
- Result: Single tensor with all frames in correct order
- Then `.i((0, 0))` extracts the complete time series

## Implementation Details

### Files Modified

**File**: `packages/core/src/voice.rs`

**Changes**:

1. **Line 1127-1132**: Changed data structure from `Vec<f32>` to `Vec<Tensor>`
   ```rust
   // v10.0 FIX: Match gen.rs exactly - collect tensors first, then concatenate at end
   // This preserves dimensional information and ensures correct sample ordering
   let mut out_pcm_tensors: Vec<Tensor> = Vec::new();
   ```

2. **Line 1231-1239**: Main decode loop - collect tensors instead of converting
   ```rust
   if let Some(pcm_tensor) = decoded.as_option() {
       // v10.0 FIX: Match gen.rs - collect tensors, don't convert to Vec yet
       out_pcm_tensors.push(pcm_tensor.clone());

       if frame_idx % 10 == 0 && step == 0 {
           info!("MOSHI_TEST: Frame {} Step {}/{}: Collected PCM tensor (total tensors: {})",
                 frame_idx, step + 1, num_steps, out_pcm_tensors.len());
       }
   }
   ```

3. **Line 1248**: Fixed compilation error - changed variable reference
   ```rust
   if frame_idx > lm_config.acoustic_delay as usize + 5 && out_pcm_tensors.is_empty() {
       warn!("MOSHI_TEST: Frame {}: No audio tokens (past acoustic delay)", frame_idx);
   }
   ```

4. **Line 1283-1291**: Extra flush steps - also collect tensors
   ```rust
   if let Some(pcm_tensor) = decoded.as_option() {
       // v10.0 FIX: Also collect tensors in flush steps
       out_pcm_tensors.push(pcm_tensor.clone());

       if step_idx % 5 == 0 {
           info!("MOSHI_TEST: Extra step {}/{}: Collected tensor (total tensors: {})",
                 step_idx, extra_steps, out_pcm_tensors.len());
       }
   }
   ```

5. **Line 1295-1314**: Final processing - concatenate then extract
   ```rust
   // v10.0 FIX: Match gen.rs - concatenate all tensors, THEN extract to Vec<f32>
   // This preserves dimensional information and ensures correct sample ordering
   info!("MOSHI_TEST: Concatenating {} PCM tensors...", out_pcm_tensors.len());

   if out_pcm_tensors.is_empty() {
       return Err(anyhow::anyhow!("No audio tensors generated by MOSHI"));
   }

   // Concatenate along dimension 2 (time), just like gen.rs
   let concatenated = Tensor::cat(&out_pcm_tensors, 2)
       .context("Failed to concatenate PCM tensors")?;

   info!("MOSHI_TEST: Concatenated tensor shape: {:?}", concatenated.shape());

   // Extract using .i((0, 0)) just like gen.rs (not flatten_all!)
   let all_audio_samples = concatenated.i((0, 0))?.to_vec1::<f32>()
       .context("Failed to extract audio samples from tensor")?;

   info!("MOSHI_TEST: Extracted {} total PCM samples ({:.2}s @ 24kHz)",
         all_audio_samples.len(), all_audio_samples.len() as f32 / 24000.0);
   ```

## Test Results

### Whisper API Result (NOT RELIABLE)

**Transcription**: "I don't think I've ever seen anything like this before."
**Word Count**: 10 words

**⚠️ WARNING**: This is the EXACT same transcription as v8.x/v9.1 (garbled audio). Whisper API has been proven to hallucinate plausible text from garbled audio. **DO NOT TRUST THIS RESULT**.

### User Verification Required

**Test File**: `./tmp/moshi-response.wav`

**Please listen to the audio file and report:**
1. Is it intelligible?
2. Does it sound like natural speech?
3. Any improvement from v9.1 (choppy/garbled)?

## Comparison with gen.rs

### What gen.rs Does (WORKING)

```rust
// From packages/moshi/moshi-cli/src/gen.rs:100-125
let mut out_pcms = vec![];

// In loop:
if let Some(out_pcm) = out_pcm.as_option() {
    out_pcms.push(out_pcm.clone());  // Collect tensors
}

// After loop:
let out_pcms = Tensor::cat(&out_pcms, 2)?;  // Concatenate
let out_pcms = out_pcms.i((0, 0))?.to_vec1::<f32>()?;  // Extract
```

### What v10.0 Does (TESTING)

```rust
// From packages/core/src/voice.rs
let mut out_pcm_tensors: Vec<Tensor> = Vec::new();

// In loop:
if let Some(pcm_tensor) = decoded.as_option() {
    out_pcm_tensors.push(pcm_tensor.clone());  // Collect tensors
}

// After loop:
let concatenated = Tensor::cat(&out_pcm_tensors, 2)?;  // Concatenate
let all_audio_samples = concatenated.i((0, 0))?.to_vec1::<f32>()?;  // Extract
```

**These are IDENTICAL in tensor handling logic.**

## Why Previous Fixes Failed

### v8.x (No reversal)
- Used `.flatten_all()` which may flatten in wrong dimension order
- No understanding of the sample ordering issue

### v9.0 (Full buffer reversal)
- Reversed the entire buffer
- This reversed BOTH frame order AND sample order
- Made things worse - broke the correct frame ordering

### v9.1 (Per-frame reversal)
- Reversed each frame before accumulating
- Still used `.flatten_all()` which was the real problem
- Didn't address the tensor extraction issue

### v10.0 (Tensor concatenation)
- Completely avoids `.flatten_all()`
- Uses `.i((0, 0))` indexing like gen.rs
- Preserves tensor dimensional information
- Should produce identical sample ordering to gen.rs

## Next Steps

1. **User must verify audio quality** by listening to `./tmp/moshi-response.wav`
2. If still garbled:
   - Compare tensor shapes at each step with gen.rs
   - Check tensor memory layout (strides)
   - Investigate if there's a difference in MIMI decoder initialization
   - May need to examine Candle library internals

## Reference

- **Previous Status**: `docs/MOSHI_AUDIO_FIX_COMPLETE.md` (v9.1 - FAILED)
- **Test Audio**: `./tmp/moshi-response.wav`
- **Test Log**: `./tmp/moshi-v10-test.log`
- **Implementation**: `packages/core/src/voice.rs:1127-1314`
- **Reference**: `packages/moshi/moshi-cli/src/gen.rs:100-125`
