# xSwarm-boss Environment Configuration
# Copy this file to .env and fill in your values

# =============================================================================
# GPU Provider Configuration
# =============================================================================
# Choose your GPU provider(s) for AI inference when local GPU is unavailable

# RunPod Serverless (Recommended for development)
# https://www.runpod.io/
# Cost: ~$0.00011-$0.00016 per second
RUNPOD_API_KEY=your_runpod_api_key_here
RUNPOD_ENDPOINT_ID=your_endpoint_id_here

# Anthropic API (Claude) - RECOMMENDED for development
# https://console.anthropic.com/
# Free tier available, best for text responses
ANTHROPIC_API_KEY=your_anthropic_key_here

# OpenAI API (GPT models + Realtime Voice API)
# https://platform.openai.com/
# Required for: Direct voice-to-voice interface (GPT-4 Realtime API)
OPENAI_API_KEY=your_openai_key_here

# Modal Labs (Python-focused, good for indexer)
# https://modal.com/
MODAL_TOKEN_ID=your_modal_token_id
MODAL_TOKEN_SECRET=your_modal_token_secret

# =============================================================================
# GPU Fallback Chain
# =============================================================================
# Comma-separated list of providers to try in order
# Options: local, runpod, modal, anthropic, openai
GPU_FALLBACK=runpod,anthropic

# =============================================================================
# Local LLM Configuration (if using local GPU)
# =============================================================================
USE_LOCAL_GPU=false
LLAMA_CPP_PATH=/usr/local/bin/llama-server
LLAMA_MODEL_PATH=~/.local/share/xswarm/models/

# =============================================================================
# Service Configuration
# =============================================================================

# Meilisearch
MEILI_MASTER_KEY=your_secure_master_key_here
MEILISEARCH_URL=http://localhost:7700

# LibSQL / Turso
LIBSQL_URL=http://localhost:8080
LIBSQL_AUTH_TOKEN=your_libsql_token_here

# =============================================================================
# xSwarm Configuration
# =============================================================================

# Overlord (orchestrator) settings
XSWARM_THEME=hal-9000
XSWARM_VOICE_ENABLED=true
XSWARM_WAKE_WORD=hey hal

# =============================================================================
# Voice Interface Options
# =============================================================================

# Option 1: OpenAI Realtime API (Voice-to-Voice) - RECOMMENDED
# Direct voice conversation with personality, no TTS needed
# Requires: OPENAI_API_KEY
# Cost: ~$0.06/min for audio input, ~$0.24/min for audio output
VOICE_PROVIDER=openai_realtime
VOICE_MODEL=gpt-4o-realtime-preview
VOICE_INSTRUCTIONS_INCLUDE_PERSONALITY=true

# Option 2: Traditional STT + LLM + TTS Pipeline
# Speech-to-Text → Claude/GPT → Text-to-Speech
# More control but slower, requires multiple API calls
# VOICE_PROVIDER=pipeline
# STT_PROVIDER=openai_whisper  # or deepgram, assemblyai
# LLM_PROVIDER=anthropic       # or openai
# TTS_PROVIDER=elevenlabs      # or openai_tts, google_tts

# ElevenLabs (for TTS in pipeline mode)
# https://elevenlabs.io/
# Best quality TTS, can clone voices
# ELEVENLABS_API_KEY=your_elevenlabs_key_here
# ELEVENLABS_VOICE_ID=your_voice_id_here

# Deepgram (alternative STT provider)
# https://deepgram.com/
# Fast, accurate speech-to-text
# DEEPGRAM_API_KEY=your_deepgram_key_here

# Wake Word Detection (local, no API needed)
WAKE_WORD_ENGINE=porcupine  # or snowboy, pvporcupine
WAKE_WORD_SENSITIVITY=0.5   # 0.0 to 1.0

# Audio Settings
AUDIO_INPUT_DEVICE=default
AUDIO_OUTPUT_DEVICE=default
AUDIO_SAMPLE_RATE=16000

# Vassal (worker) settings
XSWARM_VASSAL_NAME=speedy
XSWARM_VASSAL_HOST=0.0.0.0
XSWARM_VASSAL_PORT=9000

# Security
XSWARM_MEMORY_PURGE_INTERVAL=60
XSWARM_SECRET_DETECTION=true

# =============================================================================
# Development Settings
# =============================================================================
RUST_LOG=info
RUST_BACKTRACE=1
